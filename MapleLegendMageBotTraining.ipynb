{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "import os\n",
    "from collections import Counter\n",
    "from FeedForwardNeuroNet import MultiLayerNeuroNet\n",
    "from random import shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Data_raw1 = np.load(\"training_data5.npy\")\n",
    "Data_raw2 = np.load(\"training_data4.npy\")\n",
    "Data_raw3 = np.load(\"training_data3.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(82085, 2)\n",
      "(108, 160)\n",
      "[0, 1, 0, 0, 0, 0, 0, 0, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "#merge Data\n",
    "Data_merge = np.append(Data_raw1,Data_raw2, axis = 0)\n",
    "Data_merge = np.append(Data_merge,Data_raw3, axis = 0)\n",
    "#free up memory\n",
    "del Data_raw1\n",
    "del Data_raw2\n",
    "del Data_raw3\n",
    "print(Data_merge.shape)\n",
    "print(Data_merge[0][0].shape)\n",
    "print(Data_merge[0][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame(Data_merge)\n",
    "print(Counter(df[1].apply(str)))\n",
    "#Labels name\n",
    "#  0     1   2   3   4     5     6         7        8      9\n",
    "#[Left,Right,Up, X,LeftX,RightX,LeftUpX,RightUpX, DownX,Skill1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(82085, 1080)\n",
      "(82085, 10)\n"
     ]
    }
   ],
   "source": [
    "m = Data_merge.shape[0]\n",
    "DataX = np.empty((m,1080))\n",
    "DataY = np.zeros((m,10))\n",
    "for i in range(m):\n",
    "    data = Data_merge[i]\n",
    "    DataX[i] = np.reshape(np.resize(data[0],(27,40)), (1,1080))\n",
    "    DataY[i] = np.array(data[1])\n",
    "print(DataX.shape)\n",
    "print(DataY.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "del Data_merge\n",
    "def normalize(X):\n",
    "    return X/255\n",
    "\n",
    "Model1 = MultiLayerNeuroNet(normalize(DataX), DataY, 1080, 680, 10, .5, None,\"ReLU\", \"softmax\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.407351328774\n",
      "0.400064971981\n"
     ]
    }
   ],
   "source": [
    "print(Model1.accuracy(Model1.X_train,Model1.y_train))\n",
    "print(Model1.accuracy(Model1.X_cv, Model1.y_cv))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Shade\\Documents\\Summer2017\\MapleLegendAI\\FeedForwardNeuroNet.py:95: RuntimeWarning: divide by zero encountered in log\n",
      "  J = np.log(y*a2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost 2.32575970017\n",
      "Cost 4.21834302143\n",
      "Cost 1.64637199243\n",
      "Cost 1.65903082935\n",
      "Cost 1.5793975761\n",
      "Cost 1.57065345874\n",
      "Cost 1.59156454673\n",
      "Cost 1.54784481455\n",
      "Cost 1.54438973121\n",
      "Cost 1.54049847541\n",
      "Cost 1.53658755772\n",
      "Cost 1.53048794447\n",
      "Cost 1.52410213712\n",
      "Cost 1.51299237774\n",
      "Cost 1.51066075414\n",
      "Cost 1.50292299845\n",
      "Cost 1.50022524243\n",
      "Cost 1.5035262028\n",
      "Cost 1.49744782674\n",
      "Cost 1.49627126144\n",
      "Cost 1.49784912293\n",
      "Cost 1.496209435\n",
      "Cost 1.49693026537\n",
      "Cost 1.49622443766\n",
      "Cost 1.50237600049\n",
      "Cost 1.4961832189\n",
      "Cost 1.50082892346\n",
      "Cost 1.49621670299\n",
      "Cost 1.49611710429\n",
      "Cost 1.49613348196\n",
      "Cost 1.50061570052\n",
      "Cost 1.49568099546\n",
      "Cost 1.49247572476\n",
      "Cost 1.48815159355\n",
      "Cost 1.48126368713\n",
      "Cost 1.47848008811\n",
      "Cost 1.47667113917\n",
      "Cost 1.47473409711\n",
      "Cost 1.47324089624\n",
      "Cost 1.47116163184\n",
      "Cost 1.46654331061\n",
      "Cost 1.46368682584\n",
      "Cost 1.53638559939\n",
      "Cost 1.46264601975\n",
      "Cost 1.46295313666\n",
      "Cost 1.46187495209\n",
      "Cost 1.46395190766\n",
      "Cost 1.46043596769\n",
      "Cost 1.46861234363\n",
      "Cost 1.45929205876\n",
      "Cost 1.4635121931\n",
      "Cost 1.45878650463\n",
      "Cost 1.46013040295\n",
      "Cost 1.45827832731\n",
      "Cost 1.46018972484\n",
      "Cost 1.45745813494\n",
      "Cost 1.49352963125\n",
      "Cost 1.45640090181\n",
      "Cost 1.46792229995\n",
      "Cost 1.45591729698\n",
      "Cost 1.66580449384\n",
      "Cost 1.46411068406\n",
      "Cost 1.45529220885\n",
      "Cost 1.45830842707\n",
      "Cost 1.45518753888\n",
      "Cost 1.45644818252\n",
      "Cost 1.45521956397\n",
      "Cost 1.45518929178\n",
      "Cost 1.45518753888\n",
      "Cost 7.8115050018\n",
      "Cost 2.03350200497\n",
      "Cost 1.49519808949\n",
      "Cost 1.45582859703\n",
      "Cost 1.45517134178\n",
      "Cost 1.45544445317\n",
      "Cost 1.4551842008\n",
      "Cost 1.45517290739\n",
      "Cost 1.45517134178\n",
      "Cost 1.86196875274\n",
      "Cost 1.48757698143\n",
      "Cost 1.45591358609\n",
      "Cost 1.45511095001\n",
      "Cost 1.45544650122\n",
      "Cost 1.45511324694\n",
      "Cost 1.45510906798\n",
      "Cost 1.45510955717\n",
      "Cost 1.4551084797\n",
      "Cost 1.45510864041\n",
      "Cost 1.4551083456\n",
      "Cost 1.4551083456\n",
      "Cost 1.90061395461\n",
      "Cost 1.48718308883\n",
      "Cost 1.45650431002\n",
      "Cost 1.45506043305\n",
      "Cost 1.45570315499\n",
      "Cost 1.45509808882\n",
      "Cost 1.45506463186\n",
      "Cost 1.45506043305\n",
      "Cost 8.63464187198\n",
      "Cost 1.80940909032\n",
      "Cost 1.48544475447\n",
      "Cost 1.45640545667\n",
      "Cost 1.45512940056\n",
      "Cost 1.45506809411\n",
      "Cost 1.45506173304\n",
      "Cost 1.45506068909\n",
      "Cost 1.45506048571\n",
      "Cost 1.45506044397\n",
      "Cost 1.4550604353\n",
      "Cost 1.45506043351\n",
      "Cost 1.45506043314\n",
      "Cost 1.45506043307\n",
      "Cost 1.45506043305\n",
      "Cost 1.45506043305\n",
      "Cost 1.45506043305\n",
      "Cost 1.45506043305\n",
      "Cost 1.45506043305\n",
      "Cost 1.45506043305\n",
      "Cost 5.67830270236\n",
      "Cost 1.48415626999\n",
      "Cost 1.45375428728\n",
      "Cost 1.45160903374\n",
      "Cost 1.44825208529\n",
      "Cost 1.44737793825\n",
      "Cost 1.44730428271\n",
      "Cost 1.4464908675\n",
      "Cost 1.4460394623\n",
      "Cost 1.44747150007\n",
      "Cost 1.44511895233\n",
      "Cost 1.45057266598\n",
      "Cost 1.44475861121\n",
      "Cost 1.4531436982\n",
      "Cost 1.44477005203\n",
      "Cost 1.444713128\n",
      "Cost 1.44471387791\n",
      "Cost 1.45420962623\n",
      "Cost 1.44493063616\n",
      "Cost 1.44471344369\n",
      "Cost 1.44471189305\n",
      "Cost 1.44471138026\n",
      "Cost 1.44471256278\n",
      "Cost 1.44471156928\n",
      "Cost 1.44471138026\n",
      "Cost 1.45451982658\n",
      "Cost 1.44489941715\n",
      "Cost 1.44469256095\n",
      "Cost 1.44478095501\n",
      "Cost 1.44469501106\n",
      "Cost 1.44469240647\n",
      "Cost 1.44469356418\n",
      "Cost 1.44469246517\n",
      "Cost 1.44469240647\n",
      "Cost 1.45592247661\n",
      "Cost 1.44495589902\n",
      "Cost 1.44466908171\n",
      "Cost 1.44479496526\n",
      "Cost 1.44467466899\n",
      "Cost 1.44466929652\n",
      "Cost 1.44466908171\n",
      "Cost 1.49357775029\n",
      "Cost 1.44523563679\n",
      "Cost 1.44469586502\n",
      "Cost 1.44467158772\n",
      "Cost 1.44466947314\n",
      "Cost 1.44466915745\n",
      "Cost 1.44466909724\n",
      "Cost 1.44466908492\n",
      "Cost 1.44466908237\n",
      "Cost 1.44466908185\n",
      "Cost 1.44466908174\n",
      "Cost 1.44466908171\n",
      "Cost 1.44466908171\n",
      "Cost 1.44466908171\n",
      "Cost 1.44466908171\n",
      "Cost 1.44466908171\n",
      "Cost 1.44466908171\n",
      "Cost 1.44466908171\n",
      "Cost 1.44466908171\n",
      "Cost 1.44466908171\n",
      "Cost 13.698640019\n",
      "Cost 1.51061633088\n",
      "Cost 1.44463790044\n",
      "Cost 1.4431827964\n",
      "Cost 1.44299834171\n",
      "Cost 1.44258023511\n",
      "Cost 1.44221781548\n",
      "Cost 1.4417876053\n",
      "Cost 1.44172646257\n",
      "Cost 1.44131620324\n",
      "Cost 1.44090510253\n",
      "Cost 1.44028631547\n",
      "Cost 1.43860356309\n",
      "Cost 1.43764224792\n",
      "Cost 1.4480642114\n",
      "Cost 1.43692855207\n",
      "Cost 1.43689026566\n",
      "Cost 1.45654054502\n",
      "Cost 1.43725100527\n",
      "Cost 1.43677488308\n",
      "Cost 1.43693043356\n",
      "Cost 1.43675938836\n",
      "Cost 1.44741623944\n",
      "Cost 1.43623155505\n",
      "Cost 1.51346054899\n",
      "Cost 1.44015746719\n",
      "Cost 1.43624771554\n",
      "Cost 1.43620451554\n",
      "Cost 1.43620713709\n",
      "Cost 1.43619719795\n",
      "Cost 1.43619669976\n",
      "Cost 1.43620271631\n",
      "Cost 1.4361976851\n",
      "Cost 1.43619669976\n",
      "Cost 1.44424433379\n",
      "Cost 1.43474981928\n",
      "Cost 1.43474981928\n",
      "successfully trained the model\n",
      "Final Cost for this model is: 1.43474981928\n"
     ]
    }
   ],
   "source": [
    "Model2 = MultiLayerNeuroNet(normalize(DataX), DataY, 1080, 1080, 10, 0, None,\"ReLU\", \"softmax\")\n",
    "Model2.train(70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Shade\\Documents\\Summer2017\\MapleLegendAI\\FeedForwardNeuroNet.py:95: RuntimeWarning: divide by zero encountered in log\n",
      "  J = np.log(y*a2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost 1.43474981928\n",
      "Cost 13.6457569229\n",
      "Cost 1.58280486524\n",
      "Cost 1.43372877182\n",
      "Cost 1.43194511687\n",
      "Cost 1.43119437457\n",
      "Cost 1.43034315534\n",
      "Cost 1.42995380366\n",
      "Cost 1.4292420901\n",
      "Cost 1.42846264907\n",
      "Cost 1.42837218526\n",
      "Cost 1.42754702039\n",
      "Cost 1.43200053515\n",
      "Cost 1.42742379802\n",
      "Cost 4.95415054202\n",
      "Cost 1.49666388169\n",
      "Cost 1.42866641178\n",
      "Cost 1.42747307673\n",
      "Cost 1.4274282824\n",
      "Cost 1.42742450236\n",
      "Cost 1.42742393338\n",
      "Cost 1.42742382556\n",
      "Cost 1.4274238037\n",
      "Cost 1.4274237992\n",
      "Cost 1.42742379827\n",
      "Cost 1.42742379807\n",
      "Cost 1.42742379803\n",
      "Cost 1.42742379803\n",
      "Cost 1.42742379802\n",
      "Cost 1.42742379802\n",
      "Cost 1.42742379802\n",
      "Cost 1.42742379802\n",
      "Cost 1.42742379802\n",
      "Cost 1.42742379802\n",
      "Cost 9.84065380575\n",
      "Cost 1.67722578891\n",
      "Cost 1.43473333647\n",
      "Cost 1.42668245425\n",
      "Cost 1.42624925665\n",
      "Cost 1.4261463485\n",
      "Cost 1.42561317975\n",
      "Cost 1.42552291861\n",
      "Cost 1.42550328647\n",
      "Cost 1.42517315684\n",
      "Cost 1.42479495744\n",
      "Cost 1.42609839352\n",
      "Cost 1.42469961454\n",
      "Cost 1.42469958862\n",
      "Cost 1.42509554296\n",
      "Cost 1.42472542328\n",
      "Cost 1.42470331287\n",
      "Cost 1.42469958862\n",
      "Cost 1.42454347888\n",
      "Cost 1.42846663666\n",
      "Cost 1.42466567804\n",
      "Cost 1.42455456706\n",
      "Cost 1.42454521532\n",
      "Cost 1.42454347888\n",
      "Cost 2.01149898467\n",
      "Cost 1.42487966005\n",
      "Cost 1.42456956965\n",
      "Cost 1.42454736306\n",
      "Cost 1.4245442154\n",
      "Cost 1.42454362657\n",
      "Cost 1.42454350893\n",
      "Cost 1.42454348499\n",
      "Cost 1.42454348013\n",
      "Cost 1.42454347914\n",
      "Cost 1.42454347893\n",
      "Cost 1.42454347889\n",
      "Cost 1.42454347888\n",
      "Cost 1.42454347888\n",
      "Cost 1.42454347888\n",
      "Cost 1.42454347888\n",
      "Cost 1.42454347888\n",
      "Cost 1.42454347888\n",
      "Cost 1.42454347888\n",
      "Cost 1.42454347888\n",
      "Cost 2.2363585306\n",
      "Cost 1.46452826174\n",
      "Cost 1.42645997665\n",
      "Cost 1.42439705444\n",
      "Cost 1.42430359138\n",
      "Cost 1.42402836585\n",
      "Cost 1.42524118779\n",
      "Cost 1.42369778552\n",
      "Cost 1.42385544674\n",
      "Cost 1.42362548682\n",
      "Cost 1.42356897178\n",
      "Cost 1.42378285714\n",
      "Cost 1.42357823237\n",
      "Cost 1.42356913559\n",
      "Cost 1.42356892246\n",
      "Cost 1.42356899327\n",
      "Cost 1.42356891482\n",
      "Cost 1.42356894769\n",
      "Cost 1.42356891561\n",
      "Cost 1.42356891471\n",
      "Cost 1.42356891508\n",
      "Cost 1.42356891471\n",
      "Cost 1.42365097735\n",
      "Cost 1.42353877287\n",
      "Cost 1.42390142435\n",
      "Cost 1.42349672972\n",
      "Cost 1.42453299496\n",
      "Cost 1.42347864071\n",
      "Cost 1.42545033211\n",
      "Cost 1.42353755383\n",
      "Cost 1.42347793407\n",
      "Cost 1.42350619978\n",
      "Cost 1.42348031978\n",
      "Cost 1.42347828114\n",
      "Cost 1.42347793407\n",
      "Cost 1.43138790552\n",
      "Cost 1.42372276144\n",
      "Cost 1.42346357053\n",
      "Cost 1.42357787638\n",
      "Cost 1.42347006147\n",
      "Cost 1.42346419682\n",
      "Cost 1.42346357053\n",
      "Cost 1.43213356964\n",
      "Cost 1.42375039238\n",
      "Cost 1.42346688623\n",
      "Cost 1.42346193113\n",
      "Cost 1.42346321541\n",
      "Cost 1.42346157154\n",
      "Cost 1.42346211887\n",
      "Cost 1.42346151627\n",
      "Cost 1.42346177043\n",
      "Cost 1.42346152296\n",
      "Cost 1.42346151627\n",
      "Cost 1.58706049385\n",
      "Cost 1.4239249086\n",
      "Cost 1.42344224507\n",
      "Cost 1.42365696176\n",
      "Cost 1.42345250595\n",
      "Cost 1.42344319456\n",
      "Cost 1.42344224507\n",
      "Cost 45.5336290321\n",
      "Cost 5.42636439363\n",
      "Cost 1.54579883444\n",
      "Cost 1.42428110974\n",
      "Cost 1.42346958395\n",
      "Cost 1.42344371647\n",
      "Cost 1.42344237606\n",
      "Cost 1.42344226524\n",
      "Cost 1.42344224897\n",
      "Cost 1.42344224587\n",
      "Cost 1.42344224524\n",
      "Cost 1.4234422451\n",
      "Cost 1.42344224508\n",
      "Cost 1.42344224507\n",
      "Cost 1.42344224507\n",
      "Cost 1.42344224507\n",
      "Cost 1.42344224507\n",
      "Cost 1.42344224507\n",
      "Cost 1.42344224507\n",
      "Cost 1.42344224507\n",
      "Cost 6.54040263037\n",
      "Cost 1.6948254071\n",
      "Cost 1.43813589894\n",
      "Cost 1.42402998068\n",
      "Cost 1.42314194989\n",
      "Cost 1.42295330527\n",
      "Cost 1.42295330527\n",
      "successfully trained the model\n",
      "Final Cost for this model is: 1.42295330527\n"
     ]
    }
   ],
   "source": [
    "Model2.train(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.406916235925\n",
      "0.401323804109\n"
     ]
    }
   ],
   "source": [
    "print(Model2.accuracy(Model2.X_train,Model2.y_train))\n",
    "print(Model2.accuracy(Model2.X_cv, Model2.y_cv))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.save(\"DataX.npy\", DataX)\n",
    "np.save(\"DataY.npy\", DataY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
